Loaded corpus with 800000 lines.
Training LM with bpe tokenizer...
Training LM...
Counting number of sentences...
Counting ngrams and next tokens... 
Evaluating perplexity for bpe tokenizer with no smoothing
Average perplexity for bpe: 395.46
Evaluating perplexity for bpe tokenizer with Kneser-Key smoothing
Average perplexity with Kneser-Key for bpe: 277.95
Evaluating perplexity for bpe tokenizer with Witten-Bell smoothing
Average perplexity with Witten-Bell for bpe: 303.62
Training LM with rxt tokenizer...
Training LM...
Counting number of sentences...
Counting ngrams and next tokens... 
Evaluating perplexity for rxt tokenizer with no smoothing
Average perplexity for rxt: 2230.58
Evaluating perplexity for rxt tokenizer with Kneser-Key smoothing
Average perplexity with Kneser-Key for rxt: 611.93
Evaluating perplexity for rxt tokenizer with Witten-Bell smoothing
Average perplexity with Witten-Bell for rxt: 686.09
Training LM with ws tokenizer...
Training LM...
Counting number of sentences...
Counting ngrams and next tokens... 
Evaluating perplexity for ws tokenizer with no smoothing
Average perplexity for ws: 1755.54
Evaluating perplexity for ws tokenizer with Kneser-Key smoothing
Average perplexity with Kneser-Key for ws: 530.34
Evaluating perplexity for ws tokenizer with Witten-Bell smoothing
Average perplexity with Witten-Bell for ws: 589.95
